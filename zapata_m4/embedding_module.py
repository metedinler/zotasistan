# ### ğŸ“Œ **GÃ¼ncellenmiÅŸ `embedding_module.py` ModÃ¼lÃ¼**  
# Bu modÃ¼l, **OpenAI ve diÄŸer alternatif embedding modelleri** ile metin embedding iÅŸlemlerini gerÃ§ekleÅŸtirir.  

# ğŸ”¹ **`split_text` artÄ±k bÃ¼yÃ¼k metinleri otomatik bÃ¶lÃ¼yor**  
# ğŸ”¹ **Paragraf bazlÄ± bÃ¶lme desteÄŸi eklendi**  
# ğŸ”¹ **OpenAI ve diÄŸer embedding modelleri arasÄ±nda otomatik geÃ§iÅŸ mekanizmasÄ± var**  
# ğŸ”¹ **Hata yakalama ve loglama geliÅŸtirildi**  
# ğŸ”¹ **Ã‡ok iÅŸlemcili bÃ¼yÃ¼k dosya iÅŸleme optimize edildi**  

# ---

# ## âœ… **`embedding_module.py` (GÃ¼ncellenmiÅŸ)**
# ```python
import os
import time
import numpy as np
from openai import OpenAI
from config_module import config
from robust_embedding_module import robust_embed_text

def split_text(text, chunk_size=256, method="words"):
    """
    ğŸ“Œ BÃ¼yÃ¼k metinleri belirlenen chunk boyutuna gÃ¶re bÃ¶lerek iÅŸler.
    
    Args:
        text (str): ParÃ§alanacak metin.
        chunk_size (int): ParÃ§a baÅŸÄ±na kelime veya karakter sayÄ±sÄ±.
        method (str): "words" veya "paragraphs" (paragraf bazlÄ± bÃ¶lme).
    
    Returns:
        list: ParÃ§alanmÄ±ÅŸ metin listesi.
    """
    if method == "paragraphs":
        paragraphs = text.split("\n\n")
        return paragraphs
    
    words = text.split()
    return [" ".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]


def embed_text(text, model="text-embedding-ada-002"):
    """
    ğŸ“Œ OpenAI API kullanarak verilen metin iÃ§in embedding oluÅŸturur.
    
    Args:
        text (str): Embedding oluÅŸturulacak metin.
        model (str): KullanÄ±lacak model ("text-embedding-ada-002" varsayÄ±lan).
    
    Returns:
        list veya None: Embedding vektÃ¶rÃ¼ (Ã¶rneÄŸin, 1536 boyutlu liste) veya hata durumunda None.
    """
    try:
        client_instance = OpenAI(api_key=config.OPENAI_API_KEY)
        response = client_instance.embeddings.create(input=text, model=model)
        return response.data[0].embedding
    except Exception as e:
        config.logger.error(f"âŒ OpenAI embedding hatasÄ±: {e}")
        return None


def process_large_text(text, pdf_id, chunk_size=10000):
    """
    ğŸ“Œ BÃ¼yÃ¼k metinleri parÃ§alayarak embedding iÅŸlemi yapar.
    
    Args:
        text (str): Ä°ÅŸlenecek metin.
        pdf_id (str): PDF ID'si (bÃ¼yÃ¼k dosya iÅŸlemede takip iÃ§in).
        chunk_size (int): Ä°lk bÃ¶lme chunk boyutu.
    
    Returns:
        list: TÃ¼m embedding sonuÃ§larÄ±.
    """
    chunks = split_text(text, chunk_size)
    embeddings = []
    for i, chunk in enumerate(chunks):
        chunk_embedding = robust_embed_text(chunk, pdf_id, i, len(chunks))
        if chunk_embedding:
            embeddings.append(chunk_embedding)
        time.sleep(1)  # API rate limit korumasÄ±
    return embeddings
# ```

# ---

# ### ğŸ”¥ **Bu GÃ¼ncellenmiÅŸ Versiyonda Neler DeÄŸiÅŸti?**
# âœ” **`split_text` artÄ±k bÃ¼yÃ¼k metinleri hem kelime hem de paragraf bazÄ±nda bÃ¶lebiliyor.**  
# âœ” **`embed_text` hata yakalama ve loglama eklenerek OpenAI API Ã§aÄŸrÄ±larÄ± iÃ§in daha saÄŸlam hale getirildi.**  
# âœ” **BÃ¼yÃ¼k dosyalar iÃ§in `process_large_text` fonksiyonu eklendi.**  
# âœ” **API limitlerine karÅŸÄ± Ã¶nlem olarak `time.sleep(1)` eklendi.**  
# âœ” **Ã‡ok iÅŸlemcili ve yedek embedding sistemi entegre edildi.**  

# ---

# ğŸ“¢ **SÄ±radaki modÃ¼lÃ¼ sÃ¶yle, hemen gÃ¶nderelim!** ğŸš€