import os
from pathlib import Path
import glob
import json
import numpy as np
from config_module import config
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

def query_data(query_params):
    """
    ğŸ“Œ GeliÅŸmiÅŸ veri sorgulama fonksiyonu.
    
    Bu fonksiyon, config.CLEAN_TEXT_DIR / "txt" dizininde bulunan tÃ¼m temiz metin dosyalarÄ±nÄ±
    tarayarak, kullanÄ±cÄ± tarafÄ±ndan girilen sorgu parametrelerine gÃ¶re cosine similarity hesaplamasÄ± yapar.
    
    Ä°ÅŸ AkÄ±ÅŸÄ±:
      1. Belirtilen dizindeki tÃ¼m .txt dosyalarÄ± okunur.
      2. Her dosyadan elde edilen metinler, dosya adÄ± ile birlikte bir corpus oluÅŸturur.
      3. TfidfVectorizer kullanÄ±larak metinler vektÃ¶rleÅŸtirilir.
      4. KullanÄ±cÄ±nÄ±n sorgusu da aynÄ± ÅŸekilde vektÃ¶rleÅŸtirilir.
      5. Cosine similarity hesaplanarak en yÃ¼ksek skorlu sonuÃ§lar sÄ±ralanÄ±r.
      6. Her sonuÃ§ iÃ§in dosya adÄ±, benzerlik skoru ve ilk 200 karakterlik bir Ã¶zet (snippet) oluÅŸturulur.
    
    Args:
        query_params (str): KullanÄ±cÄ±nÄ±n sorgu olarak girdiÄŸi metin.
    
    Returns:
        dict: Sorgu sonuÃ§larÄ±nÄ± iÃ§eren sÃ¶zlÃ¼k. Ã–rnek:
              {
                  "results": [
                      {"file": "file1.txt", "similarity": 0.87, "snippet": "..." },
                      {"file": "file2.txt", "similarity": 0.75, "snippet": "..." },
                      ...
                  ]
              }
              Hata durumunda {"results": []} dÃ¶ndÃ¼rÃ¼lÃ¼r.
    """
    try:
        # Clean text dosyalarÄ±nÄ±n bulunduÄŸu dizin
        txt_dir = Path(config.CLEAN_TEXT_DIR) / "txt"
        if not txt_dir.exists():
            config.logger.error(f"Clean text dizini bulunamadÄ±: {txt_dir}")
            return {"results": []}
        
        # TÃ¼m .txt dosyalarÄ±nÄ± topla
        file_paths = list(txt_dir.glob("*.txt"))
        corpus = []
        file_names = []
        for file_path in file_paths:
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()
                    corpus.append(content)
                    file_names.append(file_path.name)
            except Exception as e:
                config.logger.error(f"Dosya okunamadÄ±: {file_path} Hata: {e}")
        
        if not corpus:
            config.logger.error("Sorgulama iÃ§in temiz metin dosyalarÄ± bulunamadÄ±.")
            return {"results": []}
        
        # TF-IDF vektÃ¶rleÅŸtirme
        vectorizer = TfidfVectorizer(max_features=1000)
        X = vectorizer.fit_transform(corpus)
        
        # Sorgu metnini vektÃ¶rleÅŸtir
        query_vec = vectorizer.transform([query_params])
        
        # Cosine similarity hesapla
        similarities = cosine_similarity(X, query_vec).flatten()
        
        # Benzerlik skoruna gÃ¶re en yÃ¼ksek sonuÃ§larÄ± sÄ±rala
        top_indices = np.argsort(similarities)[::-1]
        
        results = []
        for idx in top_indices:
            sim_score = float(similarities[idx])
            if sim_score < 0.1:
                continue  # Ã‡ok dÃ¼ÅŸÃ¼k benzerlik, atla.
            snippet = corpus[idx][:200].replace("\n", " ")  # Ä°lk 200 karakter snippet olarak alÄ±nÄ±r
            results.append({
                "file": file_names[idx],
                "similarity": round(sim_score, 4),
                "snippet": snippet
            })
        
        config.logger.info(f"Veri sorgulama tamamlandÄ±, {len(results)} sonuÃ§ bulundu.")
        return {"results": results}
    except Exception as e:
        config.logger.error(f"Veri sorgulama sÄ±rasÄ±nda hata: {e}", exc_info=True)
        return {"results": []}

AÅŸaÄŸÄ±da, tartÄ±ÅŸmalarÄ±mÄ±z ve gÃ¼ncellemeler doÄŸrultusunda oluÅŸturulmuÅŸ, 
final versiyonu olan **`data_query_module.py`** modÃ¼lÃ¼nÃ¼ bulabilirsiniz.
Bu modÃ¼l, "clean text" dosyalarÄ±nÄ±n (TXT formatÄ±nda) bulunduÄŸu dizinde arama yaparak, 
kullanÄ±cÄ± tarafÄ±ndan girilen sorgu parametrelerine gÃ¶re benzerlik analizi gerÃ§ekleÅŸtiriyor.

Ä°ÅŸ akÄ±ÅŸÄ± ÅŸu ÅŸekildedir:

1. **Veri Toplama:**  
   Belirtilen (config Ã¼zerinden ayarlanan) "clean texts" dizininde bulunan tÃ¼m TXT dosyalarÄ± okunur.  
2. **VektÃ¶rleÅŸtirme:**  
   TÃ¼m dosyalardan elde edilen metinler, TF-IDF yÃ¶ntemiyle vektÃ¶rleÅŸtirilir.  
3. **Sorgu Ä°ÅŸlemi:**  
   KullanÄ±cÄ± sorgusu da aynÄ± TF-IDF modeli kullanÄ±larak vektÃ¶rleÅŸtirilir ve cosine similarity hesaplanÄ±r.  
4. **SonuÃ§larÄ±n SÄ±ralanmasÄ±:**  
   Hesaplanan benzerlik skorlarÄ±na gÃ¶re sonuÃ§lar sÄ±ralanÄ±r.  
5. **Ã–zetleme:**  
   Her dosyadan, ilk 200 karakterlik bir Ã¶zet (snippet) alÄ±narak sonuÃ§lara eklenir.  
6. **Raporlama:**  
   SonuÃ§lar bir sÃ¶zlÃ¼k halinde dÃ¶ndÃ¼rÃ¼lÃ¼r ve ilgili iÅŸlemler loglanÄ±r.

AÅŸaÄŸÄ±da final kodu bulabilirsiniz:

# ### AÃ§Ä±klamalar

# - **ModÃ¼lÃ¼n AmacÄ±:**  
#   `query_data` fonksiyonu, temiz metin dosyalarÄ± Ã¼zerinde geliÅŸmiÅŸ veri sorgulama
# iÅŸlemleri gerÃ§ekleÅŸtirmek iÃ§in tasarlanmÄ±ÅŸtÄ±r. KullanÄ±cÄ± tarafÄ±ndan girilen sorgu metni,
# dosyalarla karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r ve benzerlik skorlarÄ±na gÃ¶re sonuÃ§lar listelenir.

# - **Fonksiyonlar:**
#   - **query_data(query_params):**  
#     - **Girdi:** KullanÄ±cÄ±nÄ±n sorgu metni.
#     - **Ä°ÅŸlev:**  
#       1. Config Ã¼zerinden belirlenmiÅŸ temiz metin dizinindeki tÃ¼m TXT dosyalarÄ± okunur.
#       2. Metinler, TfidfVectorizer kullanÄ±larak vektÃ¶rleÅŸtirilir.
#       3. Sorgu metni de aynÄ± ÅŸekilde vektÃ¶rleÅŸtirilip cosine similarity hesaplanÄ±r.
#       4. Benzerlik skorlarÄ±na gÃ¶re sonuÃ§lar sÄ±ralanÄ±r ve ilk 200 karakterlik Ã¶zet (snippet) oluÅŸturulur.
#     - **Ã‡Ä±ktÄ±:** Dosya adÄ±, benzerlik skoru ve snippet iÃ§eren sonuÃ§larÄ±n bulunduÄŸu sÃ¶zlÃ¼k.

# - **DeÄŸiÅŸkenler ve Veri YapÄ±larÄ±:**  
#   - `txt_dir`: Clean metin dosyalarÄ±nÄ±n bulunduÄŸu dizin.
#   - `corpus`: Dosya iÃ§eriklerinin listesi.
#   - `file_names`: Ä°lgili dosya adlarÄ±nÄ±n listesi.
#   - `vectorizer`: TF-IDF vektÃ¶rleÅŸtirme iÃ§in kullanÄ±lan nesne.
#   - `similarities`: Cosine similarity skorlarÄ±nÄ±n numpy arrayâ€™i.
#   - `results`: Sorgu sonucunda dÃ¶ndÃ¼rÃ¼lecek sonuÃ§larÄ±n listesi.

# - **Kontrol YapÄ±larÄ± ve Hata YÃ¶netimi:**  
#   - EÄŸer dizin veya dosyalar bulunamazsa, hata loglanÄ±r ve boÅŸ sonuÃ§ dÃ¶ndÃ¼rÃ¼lÃ¼r.
#   - Try/except bloklarÄ± kullanÄ±larak oluÅŸan tÃ¼m hatalar loglanÄ±r.

# Bu final versiyonu, Ã¶nceki tartÄ±ÅŸmalarÄ±mÄ±zdaki gereksinimleri karÅŸÄ±layacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r.
# EÄŸer ek bir geliÅŸtirme veya deÄŸiÅŸiklik talebiniz varsa, lÃ¼tfen belirtin.